# ğŸ“˜ Machine Learning Restart Journey

Welcome to my **Machine Learning Restart** repository ğŸš€

This repository contains my **day-wise learning progress** in Machine Learning, Data Science, and related concepts. It is designed as a structured roadmap from fundamentals to advanced techniques.

---

## ğŸ“‚ Repository Structure

The project is organized in a **Day-wise format**, where each folder focuses on a specific topic.

---

## ğŸ“š Theory & Conceptual Learning

Along with hands-on coding, this repository also focuses on **strong theoretical understanding** of Machine Learning concepts.

### ğŸ”¹ Covered Theory Topics
- Bias vs Variance Tradeoff
- Overfitting & Underfitting
- Gradient Descent Theory
- Loss Functions & Cost Functions
- Regularization (L1, L2, Elastic Net)
- Classification vs Regression
- Model Evaluation Metrics
- Curse of Dimensionality
- Feature Scaling Importance
- Cross Validation
- Hyperparameter Tuning
- Ensemble Theory
- Clustering Theory
- Probability & Bayes Theorem

---

## ğŸ”¹ Data Preprocessing & Feature Engineering

- Day22 â€“ Feature Standardization  
- Day22 â€“ Pandas Profiling  
- Day25 â€“ Normalization  
- Day26 â€“ Encoding  
- Day27 â€“ One Hot Encoding  
- Day28 â€“ Column Transformer  
- Day29 â€“ Pipelines  
- Day30 â€“ Function Transformer  
- Day31 â€“ Power Transform  
- Day32 â€“ Binning & Binarization  
- Day33 â€“ Handling Mixed Variables  
- Day34 â€“ Handling Date & Time  
- Day35 â€“ Complete Case Analysis  
- Day36 â€“ Imputing Numerical Data  
- Day37 â€“ Handling Missing Categorical Data  
- Day38 â€“ Missing Indicator  
- Day39 â€“ KNN Imputer  
- Day40 â€“ Iterative Imputer  
- Day42 â€“ Outlier Removal  
- Day44 â€“ Outlier Detection  
- Day45 â€“ Feature Construction  
- Day47 â€“ PCA  

---

## ğŸ”¹ Regression & Optimization

- Day48 â€“ Linear Regression  
- Day49 â€“ Regression Metrics  
- Day50 â€“ Multiple Linear Regression  
- Day51 â€“ Gradient Descent  
- Day52 â€“ Types of Gradient Descent  
- Day53 â€“ Polynomial Regression  
- Day55 â€“ Regularized Linear Regression  
- Day56 â€“ Lasso Regression  
- Day57 â€“ Elastic Net Regression  

---

## ğŸ”¹ Classification & Evaluation

- Day58 â€“ Logistic Regression  
- Day59 â€“ Classification Metrics  
- Day60 â€“ Logistic Regression (Advanced)  
- Day71 â€“ KNN  
- Day73 â€“ Kernel Trick in SVM  
- Day74 â€“ Naive Bayes  
- Day79 â€“ ROC Curves  

---

## ğŸ”¹ Tree-Based & Ensemble Learning

- Day61 â€“ Decision Trees  
- Day62 â€“ Ensembles  
- Day63 â€“ Bagging  
- Day65 â€“ Random Forest  
- Day66 â€“ AdaBoost  
- Day68 â€“ Gradient Boosting  
- Day69 â€“ Stacking  
- Day75 â€“ XGBoost  

---

## ğŸ”¹ Clustering & Unsupervised Learning

- Day67 â€“ K-Means  
- Day70 â€“ Agglomerative Hierarchical Clustering  
- Day76 â€“ DBSCAN  

---

## ğŸ”¹ Handling Imbalanced Data

- Day77 â€“ Imbalanced Dataset Techniques  

---

## ğŸ› ï¸ Tools & Technologies Used

- Python ğŸ  
- NumPy  
- Pandas  
- Matplotlib / Seaborn  
- Scikit-learn  
- Jupyter Notebook  
- VS Code  
- Git & GitHub  

---

## ğŸ¯ Purpose of This Repository

âœ” Build strong ML foundations  
âœ” Practice concepts with hands-on code  
âœ” Maintain a consistent learning routine  
âœ” Create a reference for future projects  
âœ” Track daily progress  

---

## ğŸ“ˆ Learning Progress

This repository follows a **step-by-step learning path**:

1ï¸âƒ£ Data Cleaning & Preprocessing  
2ï¸âƒ£ Feature Engineering  
3ï¸âƒ£ Regression Models  
4ï¸âƒ£ Classification Models  
5ï¸âƒ£ Ensemble Methods  
6ï¸âƒ£ Unsupervised Learning  
7ï¸âƒ£ Model Evaluation & Tuning  

---

## ğŸš€ How to Use This Repository

1. Clone the repository:

```bash
git clone <your-repo-link>
